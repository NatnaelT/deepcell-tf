{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raj lab OG pic (png) reader\n",
    "\n",
    "def _get_3D_images_from_directory(data_location, channel_names, image_size=(50,512,512), dtype='float32'):\n",
    "    \"\"\"Read all images from directory with channel_name in the filename\n",
    "\n",
    "    Args:\n",
    "        data_location (str): folder containing image files\n",
    "        channel_names (str[]): list of wildcards to select filenames\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: numpy array of each image in the directory\n",
    "    \"\"\"\n",
    "    data_format = K.image_data_format()\n",
    "    img_list_channels = []\n",
    "    for channel in channel_names:\n",
    "        img_list_channels.append(nikon_getfiles(data_location, channel))\n",
    "\n",
    "    #img_temp = np.asarray(get_image(os.path.join(data_location, img_list_channels[0][0])))\n",
    "    img_temp = np.zeros(image_size, dtype)\n",
    "\n",
    "    n_channels = len(channel_names)\n",
    "    all_images = []\n",
    "\n",
    "    for stack_iteration in range(len(img_list_channels[0])):\n",
    "\n",
    "        if data_format == 'channels_first':\n",
    "            shape = (1, n_channels, img_temp.shape[0], img_temp.shape[1], img_temp.shape[2])\n",
    "        else:\n",
    "            shape = (1, img_temp.shape[0], img_temp.shape[1], img_temp.shape[2], n_channels)\n",
    "\n",
    "        all_channels = np.zeros(shape, dtype=K.floatx())\n",
    "\n",
    "        for j in range(n_channels):\n",
    "            img_path = os.path.join(data_location, img_list_channels[j][stack_iteration])\n",
    "            channel_img = get_image(img_path)\n",
    "\n",
    "            # Images in this dataset have different dimensions along all 3 axes\n",
    "            # \n",
    "            f_dim = channel_img.shape[0] ##\n",
    "            x_dim = channel_img.shape[1] ##\n",
    "            y_dim = channel_img.shape[2] ##\n",
    "            \n",
    "            if data_format == 'channels_first':\n",
    "                all_channels[0, j, :f_dim, :x_dim, :y_dim] = channel_img\n",
    "            else:\n",
    "                all_channels[0, :f_dim, :x_dim, :y_dim, j] = channel_img\n",
    "\n",
    "        all_images.append(all_channels)\n",
    "\n",
    "    return all_images\n",
    "\n",
    "# Retrieve data and format into a numpy array of dims (batch, z, x, y, channels)\n",
    "# Note: channels 1 and 2 are input channels, channel 3 is nuclear annotations\n",
    "\n",
    "\n",
    "\n",
    "path_to_data = '/deepcell_data/users/geneva/raj_organoid_npzs/corrected/'\n",
    "channel_names = ['dapi', 'gfp', 'nuclei']\n",
    "\n",
    "raw_img_list = _get_3D_images_from_directory(path_to_data, channel_names)\n",
    "print('number of z_stacks in data is: ', len(raw_img_list))\n",
    "print('shape of each z_stack is: ', raw_img_list[0].shape)\n",
    "\n",
    "raw_img_array = np.squeeze(np.asarray(raw_img_list, dtype='float32'))\n",
    "print('final data shape is: ', raw_img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tiles in X_train and y_train that do not contain at least one cell\n",
    "X_train = list(X_train)\n",
    "y_train = list(y_train)\n",
    "X_new = []\n",
    "y_new = []\n",
    "\n",
    "for tile in range(X_train.shape[0]):\n",
    "    if y_train[tile, ...].max() > 0:\n",
    "        X_new.append(X_train[tile])\n",
    "        y_new.append(y_train[tile])\n",
    "\n",
    "X_tiles = np.asarray(X_new)\n",
    "y_tiles = np.asarray(y_new)\n",
    "\n",
    "# Clear unused space in memory\n",
    "del X_new\n",
    "del y_new\n",
    "\n",
    "print('After removing empty tiles, shape of X_tiles is {} and shape of y_tiles is {}'.format(X_tiles.shape, y_tiles.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale images along z-axis - important for calculating min_distance between centroids\n",
    "#from skimage.transform import rescale\n",
    "\n",
    "#scales = (1.0, 2.3, 1.0, 1.0, 1.0)\n",
    "\n",
    "#for semantic_head in range(len(output_images)):\n",
    "#    output_images[semantic_head] = rescale(output_images[semantic_head], scale=scale)\n",
    "\n",
    "#y_assess = rescale(y_assess, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting individual scaled cell volumes\n",
    "\n",
    "padding = 5\n",
    "\n",
    "fig = plt.figure(figsize=(15, 30))\n",
    "\n",
    "plot_masks = np.rollaxis(np.squeeze(masks), 0, 3)\n",
    "\n",
    "cell_ids = np.unique(plot_masks)[1:]\n",
    "num_cells = max(cell_ids)\n",
    "\n",
    "num_rows = int(np.ceil(num_cells / 2))\n",
    "num_cols = 2\n",
    "\n",
    "\n",
    "for cell in cell_ids:\n",
    "    \n",
    "    cell_mask = np.where(plot_masks == cell, plot_masks, 0)\n",
    "    props = regionprops(cell_mask)\n",
    "    bbox = props[0].bbox\n",
    "    \n",
    "    y_min = max(0, bbox[0] - padding)\n",
    "    y_max = bbox[3] + padding\n",
    "    x_min = max(0, bbox[1] - padding)\n",
    "    x_max = bbox[4] + padding\n",
    "    z_min = max(0, bbox[2] - padding)\n",
    "    z_max = bbox[5] + padding\n",
    "    \n",
    "    # Cell volumes\n",
    "    \n",
    "    plot_num = int(str(num_rows) + str(num_cols) + str(cell))\n",
    "    \n",
    "    ax = fig.add_subplot(plot_num, projection='3d')\n",
    "\n",
    "    ax.voxels(cell_mask[y_min:y_max, x_min:x_max, z_min:z_max], colors=color_dict[cell])\n",
    "    \n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "from skimage.feature import peak_local_max, corner_peaks\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import watershed, remove_small_objects\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "from deepcell_toolbox.utils import erode_edges\n",
    "\n",
    "def deep_watershed_3D(outputs,\n",
    "                   min_distance=10,\n",
    "                   detection_threshold=0.1,\n",
    "                   distance_threshold=0.01,\n",
    "                   exclude_border=False,\n",
    "                   small_objects_threshold=0):\n",
    "    \"\"\"Postprocessing function for deep watershed models. Thresholds the inner\n",
    "    distance prediction to find cell centroids, which are used to seed a marker\n",
    "    based watershed of the outer distance prediction.\n",
    "\n",
    "    Args:\n",
    "        outputs (list): DeepWatershed model output. A list of\n",
    "            [inner_distance, outer_distance, fgbg].\n",
    "\n",
    "            - inner_distance: Prediction for the inner distance transform.\n",
    "            - outer_distance: Prediction for the outer distance transform.\n",
    "            - fgbg: Prediction for the foregound/background transform.\n",
    "\n",
    "        min_distance (int): Minimum allowable distance between two cell centroids2.\n",
    "        detection_threshold (float): Threshold for the inner distance.\n",
    "        distance_threshold (float): Threshold for the outer distance.\n",
    "        exclude_border (bool): Whether to include centroid detections\n",
    "            at the border.\n",
    "        small_objects_threshold (int): Removes objects smaller than this size.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: Uniquely labeled mask.\n",
    "    \"\"\"\n",
    "    inner_distance_batch = outputs[0][:, ..., 0]\n",
    "    outer_distance_batch = outputs[1][:, ..., 0]\n",
    "\n",
    "    label_images = []\n",
    "    for batch in range(inner_distance_batch.shape[0]):\n",
    "        inner_distance = inner_distance_batch[batch]\n",
    "        outer_distance = outer_distance_batch[batch]\n",
    "\n",
    "        coords = peak_local_max(inner_distance,\n",
    "                                min_distance=min_distance,\n",
    "                                threshold_abs=detection_threshold,\n",
    "                                exclude_border=exclude_border)\n",
    "        \n",
    "        # Find peaks and merge equal regions        \n",
    "        markers = np.zeros(inner_distance.shape)\n",
    "        markers[coords[:, 0], coords[:, 1], coords[:,2]] = 1\n",
    "        markers = label(markers)        \n",
    "        \n",
    "        label_image = watershed(-outer_distance,\n",
    "                                markers,\n",
    "                                mask=outer_distance > distance_threshold)\n",
    "        label_image = erode_edges(label_image, 1)\n",
    "\n",
    "        # Remove small objects\n",
    "        label_image = remove_small_objects(label_image, min_size=small_objects_threshold)\n",
    "\n",
    "        # Relabel the label image\n",
    "        label_image, _, _ = relabel_sequential(label_image)\n",
    "\n",
    "        label_images.append(label_image)\n",
    "    \n",
    "    label_images = np.stack(label_images, axis=0)\n",
    "\n",
    "    return label_images\n",
    "\n",
    "                                                                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
